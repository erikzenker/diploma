\chapter{Future Work}
\label{sec:futurework}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                              %
% MORE ADAPTERS                                                                %
%                                                                              %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Further Adapter implementations}


\begin{itemize}
\item The prototype implementation (Section~\ref{sec:implementation})
  utilized MPI as communication backend. While, MPI is probably
  available on every computing system and implements probably every
  important communication protocol, also other interesting
  communication libraries could be used as communication backend.

  % Internet Socket based
\subsection*{Internet Socket Based Adapter}
\item Especially distributed system,that are not deployed on clusters,
  usually use other communication libraries than MPI.

\item Two interesting libraries are ZMQ and Boost Asio, which are
  both based on the TCP/IP and UDP/IP protocol. They can be used to
  interconnect applications over the internet. Therefore,
  computations using the internet as network are imagineable.

\item Implementing an adapter that interfaces with ZMQ or Asio would
  open an application based on the GVON interface to the world of
  distributed computing over the internet.
  
\item Examples for such applications are folding@home
  \cite{ref:folding_at_home} and seti@home
  \cite{ref:seti_at_home}. These application distribute a complex
  problem to a big number of peers over the internet.

\item A further use case is the connection of cluster nodes over the
  internet. This would construct a grid computing environment based on
  the GVON interface. It could easily extend the computational power
  of a cluster by further computing units. Whereby, all peers utilize
  the same communication interface.

  % Adapters for accelerators
\subsection*{Accelerator Based Adapter}
\item In contrast to communication over a big network such as the
  internet, is the modeling of the communication with and in between
  accelerator devices a more local issue. An adapter could model the
  mechanism of accelerator communication for CUDA or OpenCL.

\item Since, offload is a one-sided communication concept, the
  accelerator device needs to be managed from a host CPU. This host
  needs to transform the one-sided communication into a two-sided
  communication that is supported by the developed system.

\item Communication processes, such as send and receive, between
  accelerators are managed by their hosts. Therefore, the pair of host
  and device form a peer of the CAL. The transmission of data from one
  accelerator A to another accelerator B is separated into the
  following steps

  \begin{enumerate}
  \item Copy of data from A to host of A
  \item Transmission of data from host of A to host of B
  \item Copy of data from host of B to B
  \end{enumerate}

  % MPI on CUDA devices
\item This adapter for accelerators has the drawback that data has to
  take the detour above the host CPU. The emerge of CUDA version 4.0
  and 5.0 provides techniques that remove the need for the detour.

\item First of all, introduces CUDA 4.0 the Unified Virtual Addressing
  (UVA).  It creates a uniform address space of and devices of a
  single node.

\item The introduction of GPUDirect offers a direct exchange of data
  between accelerators on the same node (P2P) and of data between
  accelerator connected by a network (RDMA).  Both approaches bypass
  the CPU and exchange data directly over the PCI bus or network
  controller.

  \todo{Graphic of CUDA with GPUDirect}

  \todo{Provide small example}

\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                              %
% MULTIPLE ADAPTER                                                             %
%                                                                              %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Multiple Adapter Design}
\sitem{Until now, the adapter design is chosen deliberately}

But, the possibility to exchange the adapter of the CAL also raises
the question if a design with more than one adapter at the same time
would be possible. Connecting the network of at least two adapters
would form a heterogeneous network, where each network has its own
properties like latency, bandwidth and hardware topology. The CAL
would unify these varying networks transparently under the same
interface. Thus, a multi adapter design is the foundation for the
usage of the developed system in jungle computing environments
\ref{sec:jungle}.


\sitem{A CAL with multiple adapters could connect two cluster systems
  over internet.}

\sitem{This would create a powerful tool to extend the computing power
  of a single cluster}

\sitem{Easily create grid computing structures}

Assume, the CAL has two adapters, one for MPI and another for sockets,
to chose from and some peers of the network are able to communicate
through both adapters.  The CAL needs to provide a list of all
avaiblabe adapters for a specific peer. A particular sorting of this
list could state out the prefered adapter for communication between
two peers. Exchanging data between peers always requires a lookup of
which adapter needs to be selected to address the peers.

\sitem{On the implementation side, there are two solution to switch
  between adapters at run-time}

\sitem{strategy patter, is the run-time solution}

\todo{Inform about strategy pattern}

\sitem{variadic templates, is the compile-time solution}

Furthermore, varying real addresses spaces of different adapters have
to be mapped onto the same unified address space of the CAL.  It opens
up the possibility that two peers which do not share a same adapter,
but are connected over a third adapter, could still exchange data by
routing over that third adapter. Thus, a multi adapter design does
only make sense when routing between two adapters is implemented.

\sitem{Same problem with collective operations between varying
  adapters}

\sitem{Support of collective operations over the borders of different
  adapters in the case that the CAL supports more than one adapter
  being instantiated.}

Even if the design of a multi adapter communication abstraction layer
looks quite interesting, the implementation is rather more complex
than a single adapter design. The decision for a single or multiple
adapter CAL should be placed in the hand of the application developer.
Thus, the developer could configure the CAL by a further policy that
defines the adapter behavior.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                              %
% DEPLOYMENT IN REAL WORLD SIMULATION                                          %
%                                                                              %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Deployment in Real World Simulations}
\begin{itemize}

\item Section~\ref{sec:impl:gol} and \ref{sec:impl:nbody} have shown
  that implementations of Game of Life and N-body simulations on basis
  of the GVON are possible. Furthermore, the performance evaluation in
  Section~\ref{sec:eval:real} have shown no significant overhead in
  respect to equivalent MPI implementations.

  \subsection*{Deployment in PIConGPU}
\item PIConGPU was analyzed for the needs of a flexible communication
  approach, but was not objective for deployment.

\item The next step for evaluating the developed system is the
  deployment of the GVON as library into PIConGPU. This will show how
  well the developed system can be integrated into existing projects.


\item The PIConGPU topology is based on a three-dimensional grid with
  diagonal connections. It does not differ to much from communication
  patterns used in the GoL simulation.

\item Thus, a replacement of communication related part in PIConGPU
  source code should be easily possible.

\item PIConGPU is also interesting with respect of an CUDA-aware
  adapter.  Most calculation in PIConGPU are offloaded to the
  CPUs. Therefore, bypassing the CPU in case of device to device
  copies would increase overall performance.

  % HASEonGPU
  \subsection*{Deployment in HASEonGPU}
\item HASEonGPU is another project developed at the Helmholz Zentrum
  Dresden Rossendorf.  It was never an object of communication code
  analyses, but it would be interesting if the developed communication
  approach would easily fit on HASEonGPU.

\item HASEonGPU is Monte-Carlo simulation of photons in a laser gain
  medias. Whereby, the amplified spontaneous emission (ASE) of photons
  is calculated for certain sample points in the gain media.

\item The ASE value of each sample point can be calculated
  independently from each other. Thus, a distribution onto a cluster
  is possible.

\item In HASEonGPU a master peer distributes sample points onto
  available worker peers. This forms a communication based on a
  star-topology, where the master peer is placed as star center. In a
  scenario with a lot of workload, e.g. by lot of sample points, the
  master peer would be the communication bottleneck.
  

\item But, the utilization of the GVON would make an exchange of this
  topology very easy. The star-topology could be replaced by a more
  general tree topology. The master peer could delegate distribution
  task to sub-master peers that are responsible for sub-trees.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                              %
% GRAPH PARTITIONING                                                           %
%                                                                              %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Graph Partitioning}
\begin{itemize}

  % Load balancing
\item In the beginning of this work it was clarified, that load
  balancing is not the topic of this work. Therefore, Only rudimentary
  distribution algorithms such round robin and consecutive were
  implemented. But, it was also claimed, that it should be possible to
  build load balancing on top.

\item This and the following Section will discuss ideas for load
  balancing based on the developed system.

\item Assume, a simulation domain is modeled by an graph and the graph
  has more vertices than available peers in the global context. Peers
  need to be oversubscribed with vertices in this situation.

\item Therefore, hosted vertices on a host should be as close
  connected as possible with respect to the graph. So that,
  communication between vertices is as local as possible. This
  potentially minimizes the amount of messages that have to be
  transferred over the network.

% Graph partitioning
\item A well researched solution for this problem is partitioning of
  graphs. Partitioning divides the a graph into smaller components.
  A good partition is defined as one in which the number of edges
  running between separated components is small.

\item Since the communication topology is described by a graph, it can
  be easily partitioned by already existing graph partitioning tools.

  % Metis
  \subsection{Metis as Graph Partitioning Tool}
\item The tool METIS and its related tools hMETIS and ParMETIS are
  established applications for graph partitioning.T hey provide high
  quality partitions and are two magnitudes faster than other widely
  used partitioning algorithms compared to other graph partitioning
  tools.

\item The developers claim that Graphs with several millions of
  vertices can be partitioned in 256 parts in a few seconds on current
  generation workstations and PCs

\item Published under the Apache Licence Version 2.0. Therefore, Metis
  could be added to the graph distribution functions

  \todo{Which format does Metis need}
  \todo{How can it be deployed in existing software}
  
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                              %
% DESCRIPTION OF ADAPTER HARDWARE TOPOLOGY                                     %
%                                                                              %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Description of the Adapter Hardware Topology}
\begin{itemize}

% Cluster network topology
\item Cluster systems are equipped with varying network
  systems. Usually with custom build network topologies.  Utilizing the
  knowledge about the network topology can increase application
  performance.

\item The most general approach to describe the network topology of a
  cluster is a graph. A graph would describe physical connections
  between nodes and could be annotated with latency and bandwidth
  information.

\item This graph could be the foundation of varying graph
  algorithm. For example could the distance between two nodes be
  estimated and utilized to reduce communication latency between
  peers.
  
\item With the existence of two graphs, one modeling the communication
  topology of the simulation and another modeling the network
  topology, a mapping between these graphs is possible.
  
\item Instead a mapping from vertices to independent peers, vertices
  can be mapped onto peers modeled in the network graph. Information that were
  used to describe the network can be used to optimize this mapping.

\item In an oversubscribed case, could the communication graph first
  be partitioned to the number of available peers. After that, the
  partitions will be mapped onto the peers.

\item An optimal mapping would result in an graph
  homomorphism. Deciding whether there exists a homomorphism from one
  graph to another, is NP-complete. Therefore, a heuristically
  approach that tries to maximize the amount of same adjacent vertices
  in communication and network graph should be chosen.
  
% Load balancing
\item A Mapping between the two graphs mentioned above opens new
  possibilities for load balancing.

  % Static load balancing
\item The most simple load balancing approach is a load balancing at
  the initialization of an application. The communication graph is
  mapped only once and statically onto the network graph. This
  approach is sufficient for applications that do not change with
  respect to load distribution and the graphs.

  % Dynamic load balancing
\item But simulations can change their load distribution during
  run-time. The difference in workload could be estimated by run-time
  measurements of a single time-step. The application needs to
  initiate a rebalancing when the run-time of a host increases above a
  defined threshold.

\item A static load balancing could also be performed periodically every
  n time-steps

  % Auto tune
%% \item Create algorithm to auto tune load balancing
%% \item Generate a metric to evaluate balancing of simulation
%% \item System recognizes load imbalance and start
%%   load balancing step automatically
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                              %
% IDEAS FOR FAULT TOLERANCE                                                    %
%                                                                              %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Ideas for Fault Tolerance}
\begin{itemize}
\item Similar to load balancing was fault tolerance with respect to
  communication processes not the topic of this work. Nevertheless,
  offers the developed system the possibility to build fault tolerance
  techniques on top.

\item The main problem is the failure of a peer during execution of simulation.
  Some communication libraries such as MPI have the embarrassing behavior
  that the whole program will fail too. Therefore, the simulation has to be
  restarted, if only a single peer fails.

\item Since, the amount of computing hardware increases with each new
  cluster generation, it is not unlikely that a peer, that is host for
  vertices of a simulation, fails. The library user has usually no
  possibility to restart the failed peer, but the failed peer could be
  ignored for further communication processes.

  %Reload from checkpoint
\item Assume, that the host checkpoints the state of its hosted
  vertices at fixed points of the simulation execution. This
  checkpoints could be written onto hard disk of an network attached
  storage (NAS) or each peer could distribute the data of its hosted
  vertices to other peers for backup reasons.

\item The network of peers needs to notice the failure of the peer.
  Furthermore, the peers need estimate where the failed peer stored its
  checkpointed states.

\item Some peer has to adopt the hosted vertices of the failed host.
  This adopter peer has to announce the adopted vertices together
  with his already hosted vertices.

\item The adopter peer has to load the checkpointed states of the
  adopted vertices. In dependence whether the checkpointed state is
  up-to-date, other host do also need to load checkpointed
  states. When all vertices are synchronized to the same time-step,
  the communication and therefore the simulation algorithm can be
  continued.

\todo{Make graphics that illustrates the fault tolerance idea}

% Redundant calculations
\item Redistribute the hosted vertices of a failed host onto the
  remaining host increases the workload each host has to manage.
  
\item Instead, the vertices could be adopted by a backup peer
  that has no hosted vertices so far.

\item Equally, to the method mentioned above, needs the backup peer
  to load the checkpointed state from its adopted vertices

%% \item Another possibility without the need for reloading the check point
%%   is the redundant calculations of simulation subdomains
%% \item A vertex can be distributed to several peers
%% \item The system ensures that data receives all peers
%% \item Usage of multi-maps

\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                              %
% TWEAKS                                                                       %
%                                                                              %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Tweaks}
\begin{itemize}
\item Compile time generation of static graphs
\item Optimization of the graph to reduce overhead
\item Thread safe implementation of the gvon collectives
\item Multi-maps  
\end{itemize}

\cleardoublepage

%%% Local Variables:
%%% TeX-master: "diplom"
%%% End:
